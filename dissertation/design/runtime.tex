\section{Features of the Runtime System \label{runtime}}

\paragraph{Basic architecture.}
A minimal runtime for reactive components consists of a \emph{scheduler} and \emph{memory manager}.
The scheduler, as indicated by the model, selects actions to execute.
Time and space efficient policies for selecting an action and selecting independent actions for parallel execution are the major challenges.
The memory manager manages the allocation and deallocation of memory and the reservation of other resources like I/O ports, file descriptors, etc.
An \emph{interpreter} is necessary if the text of components is not natively executable, e.g., virtual machine bytecode.
A \emph{loader} is necessary if foreign components are loaded into the system.

\paragraph{Hosted vs. unhosted.}
A \emph{hosted} runtime is one in which the system of reactive components is executed as a process in a traditional operating system, e.g., Linux.
The advantage of this approach is the hosting environment as it provides a substantial amount of infrastructure for the runtime.
The drawback of a hosted runtime is the interface it imposes for interacting with an external environment.
For example, processes in UNIX interact with external resources by making synchronous calls on file descriptors.
A runtime for reactive components for such an enviroment would need to include file descriptors as an abstraction and functions for opening, configuring, reading, writing, and closing them.
Most likely, the runtime would provide a built-in reactive component that wraps a file descriptor.
The scheduler would include a Proactor to translate read-ready and write-ready file descriptor events into actions of the component wrapping the file descriptor.

An \emph{unhosted} runtime is an environment where reactive components are the fundamental units of computation and form an operating system.
The advantage and disadvantage of this clean-slate approach is that we are free to create our own conventions but must write every service from scratch.
I assume that the unhosted runtime would target a 32-bit or 64-bit x86 processor.
The runtime would include a built-in interrupt component that would translate physical interrupts into actions.
The programming language would need support for assembly language for interacting with the hardware.

I want to build an unhosted runtime because hardware drivers, protocol stacks, and the like will demostrate the full power or utter weakness of reactive components.
However, that is a lot of work and I want to finish more than I want to see an unhosted runtime, therefore, I will pursue a hosted runtime.
A good design should facilitate a transition from hosted to unhosted.

\paragraph{Open vs. closed.}
An \emph{open} system allows foreign components to be loaded at run time whereas a \emph{closed} system does not.
In a closed system, determinism and non-interference \emph{may} be verified at compile time.
In an open system, they \emph{must} be deferred to load time.
I will pursue a closed system, however, the verification system will be a discrete entity that can be used in either the compiler or a loader.

\paragraph{Static vs. dynamic.}
A \emph{static} system has a fixed number and configuration of components while an \emph{open} system allows new components to be created and bindings to change.
A static system \emph{can} be verified at compile time while an open system \emph{must} be verified at load time.
I will pursue a static system.

\paragraph{Interpretation vs. compilation.}
The runtime may be designed around interpretted or compiled components.
I will pursue byte-code interpretation because 1) I think it will be easier to implement than a compiler, 2) it can be designed around the constraints of reactive components, and 3) it avoids the design of a high-level programming language.
For example, we can include and exclude features that allow us to check that the state of each component is disjoint and remains disjoint.

\paragraph{Non-interference vs. communication.}
One way of enforcing non-interference is to place each component in its own virtual address space.
The drawback of this approach is that communicating components must serialize and deserialize messages as they are sent which is tedious and error prone.
Furthermore, it adds overhead every time a port is triggered.
I envision systems of hundreds or thousands of communicating components in which case the overhead becomes unacceptable.
The alternative is to place all components in the same address space which make communication easier and more efficient.
Non-interference, then, must be verified through checking.
The one-time cost of verification will be amortized over a possibly infinite number of sent messages.

Is it feasible to place all components in the same address space?
I believe the answer to this question is yes based on the following observations.
First, we have 64-bit processors which provide a huge virtual address space, one that is bigger that the physical memory available in any machine today.
Second, the working set of modern systems fits in physical memory.
(We do not operate computer systems so that they are swapping frequently.)

\paragraph{Serial vs. parallel schedulers.}
A \emph{serial} scheduler executes one action after the other so they don't overlap in time.
A \emph{parallel} scheduler may execute actions so that they overlap in time.
In addition to the analysis performed for non-determinism and non-interference, a parallel scheduler requires analysis to determine which actions are independent.
The analysis for independence is essentially the same as the analysis for non-determinism and can be done at compile time for a closed-static system.
I will pursue a parallel scheduler.

\paragraph{Exceptions.}
A programming language may be restrictive enough to avoid exceptional conditions altogether.
We may require that all exceptions that may be thrown must be caught.
If this cannot be verified, then the runtime system must be designed to deal with exceptions.
All exceptions can be related to the component in which they occur.
One strategy, then, is to disable the component throwing the exception so that none of its actions or reactions are ever executed.
This may result in a cascading failure, however, the presence of an unhandled exception indicates that the system was always unstable.

\paragraph{Pointers and memory management.}
I assume that pointers will be a first class object in the runtime and language.
If not, then the runtime/language only supports value semantics (like functional programming language) and garbage collection will be necessary to manage the lifetime of values.
Pointers must be managed to enforce non-interference.
First, every pointer must be initialized to a sound address which is either null or the address of a valid object for that pointer.
This can be accomplished by zeroing memory when it is allocated and type checking assignments.
Second, every pointer must remain a sound address.
This is accomplished through type checking assignments and preventing the formation of dangling pointers.
Dangling pointers occur in systems with manual memory deallocation when the object to which a pointer refers is destroyed but the address of the object is retained.
A dangling pointer would give a reactive component the ability to corrupt either the memory management system or another component if the object is reallocated.
Consequently, the runtime system must use garbage collection.
Third, pointers must be managed to keep the address space of each component disjoint.
This is necessary to enforce non-interference.

\paragraph{Observations about garbage collection.}
There are two observations that may be useful in the design of the garbage collector.
First, garbage collection may be performed on a component-by-component basis because the state of each component is independent of all others.
If we assume mark-and-sweep, then marking begins with the component as the root and sweeping only considers the memory that has been allocated by that component.
This suggests a two-level architecture featuring a global allocator and per-component allocator.
Each per-component allocator acts like a cache to reduce the burden on the global allocator since the global allocator is a shared resource and must be synchronized for a parallel scheduler.
Second, garbage collection can be thought of as an action.
Thus, garbage collection can be performed during an action or as an independent activity.
Garbage collection can be performed concurrently subject to independence.
Performing garbage collection during an action requires that the stack be analyzed while performing it as a separate activity requires no such analysis.

\paragraph{Shared and transfered objects.}
An object is \emph{self-contained} if the transitive closure of a points-to analysis forms a closed set identifiable by a single memory address.
Self-contained immutable objects can be shared safely among components, although, such sharing is not required for correctness.
However, if the immutable object is dynamically created, then there must be mechanisms in place to reclaim the resources associate with the object when it is no longer needed.
This implies either a reference counting scheme or system-wide garbage collection.
Reference counting is preferred since it keeps garbage collection from becoming a system-wide problem.

When triggering a port, a component may decide to transfer part of its state to another component.
To maintain non-interference, we must ensure that 1) the transferred state is a self-contained object, 2) the transferring component retains no references to this object, and 3) at most one component receives the transferred object.
If no component receives the object, the object should be reclaimed.
Figure~\ref{pointer} shows how transfered objects may be implemented.
On the sender side of the transfer, the hidden pointer is set to null while the hidden pointer on the receiver side is initialized.

\begin{figure}
{
\input pointer.tex
\centerline{\box\graph}
}
\caption{Pointer system for transferred objects.\label{pointer}}
\end{figure}
