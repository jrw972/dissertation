\section{Evaluation \label{evaluation}}

In this section, we propose a set of evaluations towards gauging the fitness of the model in section~\ref{model} and implementation in section~\ref{implementation} for designing and implementing real reactive systems.
The first evaluation applies the model of reactive components to the design and implementation of an embedded web server.
The goal is to understand the strengths and weakness of the model as it is applied to different problems in reactive systems and whether the model does indeed support principled composition and decomposition.
The various components of the embedded web server will be compared to their analogues developed using different approaches, i.e., threads and events, to gain insight into the model.
%% The topics of the case studies will be existing algorithms and systems in an effort to gain insight into the model by comparing and contrasting designs and implementations in different approaches.
The second evaluation will focus on a set of micro-benchmarks for measuring the performance of the implementation to determine if the resulting overhead of using the model is reasonable.
From the perspective of a software engineer, the first part of the evaluation provides guidance as to what to expect when using the model while the second part of the evaluation establishes the cost, i.e., overhead, of using the model.

\subsection{Qualitative Evaluation}

To determine whether (and if so how effectively) the model of section~\ref{model} and implementation of section~\ref{implementation} can facilitate the design and development of real reactive systems using principled composition and decomposition, we focus on building a real (if small-scale) reactive system using reactive components.
%% Thus, the first step in evaluating the model of section~\ref{model} is a number of case studies that apply the model to different design and implementation tasks.
%% The case studies should be grounded in a well-understood real-world problems in reactive systems.
%% Studying a well-understood problem allows us to treat the problem as a ``control'' while treating the model as the ``test'' resulting in a implementation with its own characteristics.
%% The problems should be relevant to the current state of the art and of sufficient complexity to test the model's ability to scale.
%% Furthermore, in addition to being asynchronous, the problem should have some ``obvious'' parallelism that allows one to test and evaluate the concurrency in various designs.
%% The problem should touch on a number of areas of reactive systems such an hardware, networking, interactivity, etc.
%% An embedded web server exemplifies this kind of case study.
%%\paragraph{Embedded web server.}
Specifically, we will examine an ``embedded'' web server that is constructed without the benefit or hindrance of an operating system.
Web servers have the advantage that they are both well-understood and relevant to the existing state of the art.
Focusing on a well-understood problem allows us to treat the problem as a ``control'' while treating the model as the ``test'' resulting in an implementation with its own characteristics.
While the proposed web server will not approach the sophistication of an industrial grade server, it will be of sufficient complexity to be representative of real-world problems.
Web servers also have some ``obvious'' parallelism since requests are largely independent.
An embedded web server requires the development of a network protocol stack starting at the driver level.
This provides an opportunity to touch on a number of areas in reactive systems such as hardware, networking, and remote interactivity.

\begin{figure}
{
\input webserver.tex
\centerline{\box\graph}
}
\caption{The architecture of an embedded web server\label{webserver}}
\end{figure}

Figure~\ref{webserver} shows one possible architecture for an embedded web server.
We argue that an architecture like the one shown in figure~\ref{webserver} is the beginning of a design based on principled decomposition.
Each layer can be implemented by a reactive component that interacts with the component immediately above and below it and one can envision requests propagating upward while responses propagate downward.

The lowest layer, indicated by ``I/O Driver'', represents the primitive I/O mechanisms available on a given architecture.
On the x86 architecture, for example, this includes memory mapped I/O, port I/O, and interrupts.
Using the primitive I/O mechanisms, one can construct a driver for an Ethernet network interface card.
The development of device drivers is common to reactive systems such as embedded systems and operating systems and the corresponding development of a device driver will test the model's suitability for abstracting and interacting with hardware.

\begin{figure}
{
\input ethernet.tex
\centerline{\box\graph}
}
\caption{A block diagram of the Ethernet driver and a generic client\label{ethernet}}
\end{figure}

As with existing Ethernet drivers, e.g., network device drivers in Linux~\cite{corbet2005linux}, the Ethernet driver will be built around two queues for sending and receiving Ethernet frames, respectively.
However, we expect to see two major differences with the reactive component approach.
First, we expect to see an elimination (or reduction) is the amount of synchronization code in the driver.
Device drivers in Linux must be re-entrant since the Linux kernel is multi-threaded~\cite{corbet2005linux}.
The atomicity guarantees of the model for reactive components should obviate the need for most if not all of the synchronization code.
Second, we expect a more direct interface to the Ethernet driver.
Device drivers in Linux send and receive events using function callbacks and function calls~\cite{corbet2005linux}.
A driver based on reactive components can use ports to express the same idea directly, i.e., the driver contains an input port for accepting frames to be sent and an output port for producing frames that have been received.
Figure~\ref{ethernet} shows the relationship between the Ethernet driver and a generic Ethernet client.

As is commonly done in practice, Ethernet can be used to implement the internet protocol (IP) and the transmission control protocol (TCP).
These protocols are well-understood, well-documented in precise standards, and a number of reference implementations exist, thus, the development of the corresponding components is an exercise in translating existing specifications into component implementations.
%% The operation of these intermediate networking components, i.e., Ethernet, IP, TCP, and HTTP components, is specified in precise standards.
%% The development of the corresponding components, then, is an exercise in translating existing specifications into component implementations.
%% We desire to know if existing approaches to specifying reactive systems, e.g., state machines, block diagrams, etc., have a straightforward translation to the model of section~\ref{model}.
%% The ``straightforwardness'' of a translation will be based on the conservation of features, the conservation of structure, and the conciseness of the implementation.
The experience gained by developing network protocols like IP and TCP will indicate if the model for reactive components is a good candidate for implementing other protocols.
Specifically, we expect concise and direct implementations since many protocols are specified using automata, e.g., the state transition diagram of TCP.
The congestion control algorithm of TCP also presents an interesting opportunity as we expect that different congestion control algorithms can be encode as components resulting in a pluggable architecture.

As is commonly done in practice, TCP/IP can then be used to construct a server capable of speaking the hyper-text transfer protocol (HTTP).
The HTTP server represents the generic part of the HTTP protocol, e.g., encoding/decoding messages, while the ``Web Server'' layer of figure~\ref{webserver} represents the application providing the actual content and service.
Using the embedded web server, we propose to implement a multi-user web-based chat service.
Users may either join an existing public chat room, create a new public chat room, create a private chat with an acquaintance, invite an acquaintance to a public or private chat room, or accept an invitation to join a chat room.

The HTTP server and web server of figure~\ref{webserver} are at a similar level of abstraction as many existing reactive applications since the lower layers, i.e., TCP/IP, Ethernet, etc., are typically part of the operating system.
Thus, we can compare the design of the HTTP server and web server to existing systems, e.g., the Apache web server~\cite{apache}, and existing design techniques, e.g.,~\cite{schmidt2000pattern}.
Specifically, we are interested in how various design patterns translate into the model of reactive components and the effect on the resulting architecture.
For example, we believe the model for reactive components obviate the need for the Reactor design pattern~\cite{schmidt2000pattern} due to an absence of blocking I/O operations.
Similarly, we can consider patterns that may not be possible such as the Half-Sync/Half-Async design pattern~\cite{schmidt2000pattern} which reintroduces blocking operations after they have been removed by the Reactor design pattern.
For each design, we will attempt to identify the design patterns that were applied, the motivation behind the use of a design pattern, and corresponding liabilities that accompany the use of a design pattern.
Furthermore, we would like to provide some idea as to the influence of the model and programming the language on the implementation of the pattern, i.e., does the model or language help or hinder the expression of a pattern.

%% What do we want to learn from webserver level
%%   application arena
%%   Expect no I/O translation layer

%% The operation of the intermediate networking components, i.e., Ethernet, IP, TCP, and HTTP components, is specified in precise standards.
%% The development of these components, then, is an exercise in translating existing specifications into component implementations.
%% We desire to know if existing approaches to specifying reactive systems, e.g., state machines, block diagrams, etc., have a straightforward translation to the model of section~\ref{model}.
%% The ``straightforwardness'' of a translation will be based on the conservation of features, the conservation of structure, and the conciseness of the implementation.

%% Based on these requirements we will design and implement two chat servers:  one based on the model of section~\ref{model} and the other based on threads and events and corresponding design patterns, e.g.,~\cite{schmidt2000pattern}.
%% The substance of the case study is a comparison of the design of the web server as influenced by the model of section~\ref{model} to the designs of web servers influenced by existing models, e.g., the Apache web server~\cite{apache}, the Tomcat web server~\cite{tomcat}, etc..
%% In each design, we will attempt to identify the design patterns that were applied, the motivation behind the use of a design pattern, and corresponding liabilities that accompany the use of a design pattern.
%% Furthermore, we would like to provide some idea as to the influence of the model and programming the language on the implementation of the pattern, i.e., does the model language help or hinder the expression of a pattern.

%% The web server component can range from a simple component that serves a set of static web pages to a complex component that integrates a generic database, a controlling application, and a web front-end.
%% Thus, the web server provides an opportunity to study different designs and apply principled composition and decomposition.
%% Since, different web servers often perform similar activities, we expect that a number of domain-specific components will emerge.
%% Performance is a major consideration in the design of a web server and it is important to take advantage of concurrency when possible.
%% While it is unlikely that the performance of our web server will approach the performance of industrial grade web servers, the various design and implementations can be profiled with various benchmarks to determine if the model can be used to formulate more concurrent designs.

%% Unit testing.

\subsection{Quantitative Evaluation}

The goal of the quantitative evaluation is to quantify the performance of the systems that constitute the implementation of section~\ref{implementation}.
In this regard, there are two systems of interest.
First, the compiler will rely on a number of new analyses.
Thus, we will derive complexity bounds for theses analyses but also measure the real performance of these algorithms to determine if they are feasible in practice.
Second, the performance of a system expressed as an $\alpha$-machine image is linked to the performance of the scheduler.
Thus, we will use static analysis and micro-benchmarks to measure the performance of the scheduler.

With respect to schedulers, we are interested in three quantities corresponding to the efficiency of the scheduler, the time overhead of scheduling, and the storage overhead of scheduling.
To illustrate, consider a brute-force scheduler that merely cycles through the list of $\alpha$-statements.
Such a scheduler is obviously fair but may not be efficient.
That is, the scheduler may evaluate a number of preconditions before finding an $\alpha$-statement that is enabled.
Thus, one way of measuring the efficiency of a scheduler is to compare the number preconditions that evaluate to true to the total number of evaluations.
Similarly, one could instead measure the time used to evaluate preconditions, i.e., a scheduler should avoid evaluating complex preconditions when possible.
The time overhead or computational complexity of scheduling is the time required to select the next $\alpha$-statement.
The complexity of the brute-force scheduler is $O(1)$ since the next statement to be selected is known based on the current statement.
Finally, improving the efficiency or time overhead of scheduling may require additional data structures.
The storage overhead of scheduling, then, is any overhead associated with state variables, $\alpha$-statements, etc.

For concurrent $\alpha$-machines, we must also evaluate overheads associated with synchronization.
Most likely, concurrent $\alpha$-machines will be implemented using threads as this is the native concurrency mechanism available on existing processors.
A concurrent scheduler must use synchronization primitives to coordinate the activities of the threads.
The time spent on synchronization is necessary but reduces the overall performance of the scheduler.
Single-threaded and multi-threaded schedulers may be able to take advantage of static analysis, e.g., statically partition and schedule $\alpha$-statements based on data flow, and/or dynamic analysis, i.e., use the dynamic behavior of the system to improve scheduling decisions.
