\chapter{Background and Related Work}
\label{background}

In this chapter, we first present background on the semantics of reactive systems.
We then provide a survey of other work related to this dissertation, with a particular emphasis on the UNITY and I/O Automata models upon which the approach presented here improves in specific ways.

\paragraph{Reactive semantics.}
State (memory) is fundamental to reactive systems as past inputs influence future behavior.
Baeten concludes that the first step towards developing algebraic models for reactive systems was ``abandoning the idea that a program is a transformation from input to output, replacing this by an approach where all intermediate states are important''~\cite{baeten2005brief}.
The state of a reactive system is often captured in: program variables, e.g., in Dijkstra's Cooperating Sequential Processes~\cite{dijkstra1965cooperating}; messages in a channel or queue, e.g.,  in Milner's Calculus of Communicating Systems~\cite{milner1982calculus} and in the Actor Model~\cite{agha1985actors}; or some combination of the two, e.g., in Kahn Process Networks~\cite{kahn1974semantics}.

Computation in a reactive system then can be viewed as a sequence of state transitions~\cite{pnueli1981temporal}.
As these transitions may be complex, platforms typically allow complex state transitions to be composed from primitive state transitions and complex states, e.g., arrays, records, tuples, lists, sets, etc., to be composed from primitive states.
Three orthogonal techniques for composing complex state transitions are expressions, sequential composition, and parallel composition.
\emph{Expressions} raise the level of abstraction by summarizing a computation whose intermediate results are unimportant.
A compiler or interpreter is free to schedule the evaluation of an expression in any way that preserves the semantics of the expression.
\emph{Sequential composition} is based on the idea that complex state transformations can be decomposed into a sequence of simpler state transformations.
\emph{Parallel composition} is based on the idea that complex state transformations can be composed by relating simpler state transformations, e.g., parallel assignment~\cite{barron1963main}.
Conceptually, the right-hand side (RHS) of a parallel assignment is computed before any of the variables on the left-hand side (LHS) are modified.

We distinguish between a \emph{reactive program} which is a static description of a set of transitions and a \emph{reactive process} which is the realization of the transitions of the corresponding reactive program.
State may be \emph{private} meaning that it may only be updated by a single reactive process or \emph{shared} meaning that it may be updated by multiple reactive processes.
The stack associated with a thread and thread specific storage are common examples of private state.
Shared state is often organized using abstraction where updates to shared state are exposed in the form of structured transitions as opposed to raw assignment, e.g., a method or function to place a message in a queue.
Synchronization and communication are identified as necessary activities in a reactive system~\cite{andrews1983concepts}.
The two approaches to communication are \emph{shared variables} and \emph{message passing}~\cite{andrews1983concepts}.

Multiple reactive processes effect state transitions that overlap in time, which is called \emph{concurrency}.
Simultaneous state transitions, i.e., those that overlap in real time, require parallel physical resources.
State transitions that are formed by sequential composition may be overlapped by interleaving the primitive transitions of the corresponding complex transitions.
The result of concurrent state transitions that update the same (shared) state may be undefined.
Consequently, updates to shared state must be coordinated to prevent corruption.

Platforms for reactive systems, therefore, include the notion of \emph{atomicity} which says that certain transitions may not be interrupted, i.e., executed simultaneously or interleaved with another transition.
An \emph{event} is an atomic state transition.

\emph{Non-determinism} is another inherent attribute of reactive systems that conveys the idea that the order of events in a reactive system is not fixed.
Non-determinism is typically combined with atomicity to ensure that transitions are well-defined.
In a pair of events operating on the same state, for example, atomicity says that one event will be executed before the other while non-determinism says that the order in which they are executed is not determined.
True concurrency, i.e., simultaneity, is often modeled using a non-deterministic sequence of atomic events, e.g.,~\cite{nancy1996distributed}, \cite{chandy1989parallel}, \cite{manna1992temporal}.

As a sequence of atomic transitions, a reactive process (or rather the reactive program that defines it) may either have \emph{deterministic sequencing} or \emph{non-deterministic sequencing}.
As implied by the name, the order of transitions in a reactive process with deterministic sequencing is completely determined, i.e., there is always a single next transition (or termination).
The sequence of state transitions is called a \emph{flow of control}.
Reactive processes with deterministic sequencing are often based on an (infinite) loop that repeats for the duration of the reactive process.
Influential models based on deterministic sequencing include Dijkstra's Cooperating Sequential Processes~\cite{dijkstra1965cooperating} and Hoare's Communicating Sequential Processes~\cite{hoare1978communicating}.

Conversely, the order of transitions in a reactive process with non-deterministic sequencing is not completely determined, i.e., the next transition is selected from a set of candidates.
Platforms supporting reactive processes with non-deterministic sequencing include a \emph{scheduler}, which chooses among the available transitions.
Reactive programs with deterministic sequencing correspond to a (circular) list of transitions while reactive programs with non-deterministic sequencing correspond to a set of transitions.
Deterministic sequencing and non-deterministic sequencing only describe individual reactive processes as the global choice for the next transition is in general non-deterministic.
Influential models based on non-deterministic sequencing include the UNITY model of Chandy and Misra~\cite{chandy1989parallel} and Lynch's I/O Automata~\cite{nancy1996distributed}.

Atomicity may either be \emph{explicit} or \emph{implicit} in a model for reactive systems.
Platforms that support reactive processes with deterministic sequencing and shared variables typically include primitive transitions called \emph{synchronization primitives}, e.g., test-and-set, compare-and-swap, that may atomically update state and/or alter the flow of control~\cite{andrews1983concepts}.
Synchronization primitives can be used to construct more general synchronization mechanisms like semaphores and monitors~\cite{dijkstra1965cooperating}.
The goal of synchronization is to create atomic sequences of transitions called \emph{critical regions} or \emph{critical sections}~\cite{andrews1983concepts}.
Atomicity, therefore, is made explicit by the programmer.
%% Implicit atomicity uses language constructs, e.g., the \verb+synchronized+ keyword in Java, for synchronization.
Message passing combines communication with synchronization to achieve implicit atomicity in reactive programs based on deterministic sequencing~\cite{andrews1983concepts}.
Non-deterministic sequencing requires that all transitions be atomic and therefore implies implicit atomicity.

\paragraph{Related work.}
Reactive systems are designed and implemented using shared variables and/or message passing.
A popular approach to reactive systems is the pairing of shared variables with deterministic sequencing and explicit atomicity as is done in Dijkstra's Cooperating Sequential Processes~\cite{dijkstra1965cooperating}.
Andrews and Schneider describe a number of techniques associated with this approach including coroutines, fork/join, spin locks, semaphores, conditional critical regions, and monitors~\cite{andrews1983concepts}.
This model is supported by widely available platforms, i.e., operating systems, via processes with shared memory or threads~\cite{silberschatz2005operating}.
A number of architectural patterns have been developed based on this approach, e.g.,~\cite{schmidt2000pattern}, \cite{lea2000concurrent}.
As described by Lee~\cite{lee2006problem}, support for this model can be integrated into an existing sequential language through an external library, e.g., POSIX threads, or extensions to the base language, e.g., Cilk~\cite{blumofe1995cilk}, Split-C~\cite{culler1993parallel}, C++11~\cite{cxx11}.
Sutter and Larus~\cite{sutter2005software} and Lee~\cite{lee2006problem} provide a modern perspective on the difficulties associated with this approach.
In~\cite{sutter2005software}, the authors call for ``OO for concurrency--higher-level abstractions that help build concurrent programs, just as object-oriented abstractions help build large componentized programs.''
The work presented in this dissertation is a step in this direction.

Transactional memory has been proposed as an alternative to locks when synchronizing multiple processes.
Transactional memory was inspired by the atomic transactions of databases~\cite{Eswaran:1976:NCP:360363.360369}.
Knight~\cite{Knight:1986:AMF:319838.319854} and then Herlihy and Moss~\cite{Herlihy:1993:TMA:165123.165164} proposed cache-based hardware support for transactional memory.
Transactional memory is forthcoming on modern processors~\cite{haswell}.
Software transactional memory, proposed by Shavit and Touitou~\cite{shavit1997software}, has sparked a great deal of interest and has been implemented in a number of languages, e.g., Clojure~\cite{halloway2009programming}.

Another technique for designing and implementing reactive systems that is receiving renewed interest is promises and futures~\cite{friedman1976impact, ifip1975new}.
Promises and futures represent two sides of a deferred computation.
The consumer of a deferred computation receives a future that it can later interrogate for the values produced by the deferred computation.
The producer of a deferred computation receives a promise that it later fulfills by performing the deferred computation.

Another popular approach to reactive systems is messaging passing with deterministic sequencing as is done in Hoare's Communicating Sequential Processes~\cite{hoare1978communicating}.
This model is also supported by widely available platforms via pipes, message queues, and sockets~\cite{silberschatz2005operating}.
Go is a modern programming language with language support for the Communicating Sequential Processes model~\cite{go}.
A message passing channel may either be unbounded or have a fixed size and may be accessed synchronously or asynchronously by either the sender or the receiver~\cite{andrews1983concepts}.

%% Synchronous sends block the sender until the channel is not full while asynchronous sends succeed or fail immediately.
%% Similarly, synchronous receives block the receiver until the channel is not empty while asynchronous receives succeed or fail immediately.
%% To illustrate, channels in CSP may contain one message and are accessed synchronously by both sender and receiver while channels in Kahn Process Networks~\cite{kahn1974semantics} are typically unbounded and accessed asynchronously by the sender and synchronously by the receiver.

Events, as proposed by Ousterhout~\cite{ousterhout1996threads}, and embodied in the Reactor and Proactor architectural patterns~\cite{schmidt2000pattern}, offer a popular technique for structuring user applications based on deterministic sequencing.
The application is designed around a loop that multiplexes I/O events from the operating system using a polling function like \verb+select+ or \verb+poll+.
In response to an I/O event, the application invokes an (atomic) event handler that may update the state of the process and perform non-blocking I/O on various channels.
Events invert the flow of control since high-level functions, e.g., processing a message, are triggered by low-level functions, e.g., receiving a byte.
The context of each computation must be managed explicitly which is referred to as ``stack ripping''~\cite{adya2002cooperative}.
Event handlers from different logical computations may be interleaved giving the illusion of concurrency while avoiding the challenges of synchronization.
Event systems wishing to take advantage of true concurrency must use multiple event loops and face all of the challenges of multi-threaded programming.
Node.js~\cite{Surhone:2010:NOD:1941165} and ECMA Script (JavaScript)~\cite{EcmaScript} are two modern programming languages based on an event loop.

\paragraph{UNITY and I/O Automata.}
The UNITY model of Chandy and Misra~\cite{chandy1989parallel} and the I/O Automata model of Lynch~\cite{nancy1996distributed} are two influential models for reactive systems based on non-deterministic sequencing.
In these models, a scheduler repeatedly executes transitions selected non-deterministically from the set of possible transitions.
The scheduler is assumed to be fair, meaning that it will execute a transition an infinite number of times in an infinite execution.
Transitions correspond to \emph{(parallel) assignment statements} in the UNITY model and \emph{actions} in the I/O Automata model.
The UNITY model contains two means of composing programs which suggests that a model based on non-deterministic sequencing could support principled decomposition.
Creating a program via the \emph{union} operation involves taking the union of the state variables (name-based equivalence) and assignment statements of the constituent programs.
\emph{Superposition} is a means of composition that transforms an underlying program into another.
The transformation is allowed to add new state variables, add new assignment statements with the limitation that they only update new variables, and augment existing assignment statements but only by adding clauses that modify new variables.
The size of the resulting program (measured in assignment statements) is on the order of the sum (as opposed to the product) of the sizes of the two constituent programs.
%% This somewhat matches the intuition that the result of composition should be the sum of its parts as opposed to the product of its parts.

Superposition is property-preserving while union is not property-preserving.
However, superposition has certain weaknesses, as described by the authors of UNITY~\cite{chandy1989parallel}:
\begin{quotation}
Both union and superposition are methods for structuring programs.
The union operation applies to two programs to yield a composite program.
Unlike union, a transformed program resulting from superposition cannot be described in terms of two component programs, one of which is the underlying program.
The absence of such a decomposition limits the algebraic treatment of superposition.
Furthermore, a description of augmentation seems to require intimate knowledge of statements in the underlying program.
Appropriate syntactic mechanisms should be developed to solve some of these problems.
\end{quotation}
They go on to note that a restricted form of superposition, i.e., one that only adds variables and assignment statements, is equivalent to union and can be analyzed as such.

The essence of superposition is that a transition in one program can be linked to a transition in another program, i.e., parallel composition.
Whereas UNITY lacks language support for doing so, the I/O Automata~\cite{nancy1996distributed} model presents a partial solution by associating names with transitions (actions).
Actions in different Automata can then be composed on the basis of name matching.
The I/O Automata model defines three kinds of actions:  output actions, input actions, and internal actions.
Output actions and internal actions, collectively called local actions, contain guards and may be executed by the scheduler.
Each input action must be composed with an output action to be executed.
Output actions can produce values that are consumed by input actions.
Since the state of each I/O automaton is private, composition in the I/O Automata model is property-preserving.

Of interest to this dissertation is the improvement and implementation of these ideas and their application to the design and development of reactive systems.
Granicz et al. propose a compilation method for UNITY in their Mojave compiler framework~\cite{GZH03}.
Other initiatives to implement the UNITY programming language are summarized in~\cite{GZH03}:
\begin{quotation}
Few compilers have been developed for the UNITY language.
DeRoure's parallel implementation of UNITY~\cite{deroure1991parallel} compiles UNITY to a common backend language, BSP-occam; Huber's MasPar UNITY~\cite{huber1992maspar} compiles UNITY to MPL for execution on MasPar SIMD computers; and Radha and Muthukrishnan have developed a portable implementation of UNITY for Von Neumann machines~\cite{radha1993portable}\footnote{We believe all of these projects, including~\cite{GZH03}, are now defunct.}.
\end{quotation}
Goldman's Spectrum Simulation System~\cite{goldman1990distributed} allows one to simulate systems expressed as I/O Automata.
The IOA toolkit is an implementation of I/O Automata focused on verification and simulation~\cite{ioatoolkit}.
The IOA toolkit does contain a source-to-source compiler (IOA to Java) and a run-time system that has been used to compile and execute distributed protocols~\cite{georgiou2009automated}.

\paragraph{Summary.}
Formal models of reactive systems may be organized around sequential threads with shared variables, e.g., Cooperating Sequential Processes~\cite{dijkstra1965cooperating}, sequential threads with message-passing, e.g., Communicating Sequential Processes~\cite{hoare1978communicating}, atomic transitions with shared variables, e.g., UNITY~\cite{chandy1989parallel}, and atomic transitions with message-passing, e.g., I/O Automata~\cite{nancy1996distributed}.
Models based on atomic transitions avoid reasoning about the interleaved execution of threads which may simplify reasoning about reactive systems.
Combining atomic transitions with message passing (I/O Automata) creates the opportunity for property-preserving composition which is problematic in models based on shared variables, e.g., UNITY.
The reactive component model described in Chapter~\ref{model} of this dissertation extends the property-preserving composition techniques of I/O Automata by permitting composition to an arbitrary depth and degree using the superposition technique of UNITY to link transitions in different modules in a principled way.

Reactive semantics may be introduced via libraries or built into a language.
Taking an inherently transformational language and introducing reactive semantics via a library may significantly alter the semantics of the language.
With respect to language support, an inherently transformational language may be augmented with features to support reactive semantics or the language can be designed around a particular approach to reactive systems.
Go with CSP-style primitives is an example of the former and Erlang as a realization of the Actor model is an example of the latter.
Language support has the potential to raise the level of abstraction and provides the opportunity to check and enforce reactive semantics.
To date, the main focus areas of languages designed around the atomic transition paradigm have been parallel computing and simulation.
The \rcgo{} language presented in Chapter~\ref{language} of this dissertation instead focuses on practical concerns of software engineering such a reference semantics for the efficient implementation of data structures, move semantics for efficient communication, and the isolation of state for property-preserving composition.
Similarly, there are few results concerning the design, implementation, and evaluation of fair schedulers, which are a necessary piece of run-time systems that support atomic transitions.
Chapter~\ref{implementation} of this dissertation describes the design, implementation, and evaluation of two concurrent fair schedulers.

%% Andrews and Schneider survey preliminary work in reactive systems which grew out of operating systems research and was concerned with reactive programs based on deterministic sequencing~\cite{andrews1983concepts}.
%% We argue that the ideas and techniques in \cite{andrews1983concepts}, e.g., coroutines, fork/join, spin locks, semaphores, conditional critical regions (condition variables), monitors (active objects, thread-safe interface), message passing, remote procedure call, atomic transactions (databases, software-transactional memory), are still representative of the state of the art in reactive systems.
%% Sutter and Larus~\cite{sutter2005software} and Lee~\cite{lee2006problem} provide a modern perspective on the difficulties associated with these techniques.
%% In~\cite{sutter2005software}, the authors call for ``OO for concurrency--higher-level abstractions that help build concurrent programs, just as object-oriented abstractions help build large componentized programs.''
%% The proposed work is a step in this direction.

%% Perhaps the first programs that were designed to run forever (and therefore are reactive) are the monitor programs (now called operating system kernels) of early multiprogramming systems, e.g., IBM STRETCH~\cite{codd1959multiprogramming}, and time-sharing or multitasking systems, e.g., Compatible Time-Sharing System~\cite{corbato1962experimental}.

%% Lee identifies four approaches to developing concurrent (reactive programs)~\cite{lee2006problem}.
%% One approach is to take an existing, presumably sequential, programming language and add support for concurrency via an external library, e.g., the POSIX threads library and the C programming language.
%% The advantage of this approach is that it is easily supported using standard compilers.
%% The disadvantage of this approach is the radical change in semantics.
%% Another approach is to extend an existing programming language with constructs for concurrency.
%% This solves the semantics problem but incurs the compiler problem as programmers are not inclined to use non-standard compilers.
%% A third approach is the creation of a new programming language, e.g., Erlang, Clojure, etc., based on different concurrency semantics.
%% Again, this solves the semantics problem but incurs all of the problems associated with the adoption of a new programming language.
%% The last approach is based on the use of a coordination language to coordinate the concurrent activities of various \emph{actors} which may be implemented in different languages.



%% The semantics of the library

%% Split-C~\cite{culler1993parallel}
%% Cilk~\cite{blumofe1995cilk}


%% multicore


%% Preliminary work in reactive systems grew out operating systems research and was concerned with reactive programs based on deterministic sequencing~\cite{andrews1983concepts}.




%% Synchronization and communication are identified as necessary activities in concurrent programming while correct sequencing and interference are identified as the main challenges~\cite{andrews1983concepts}.
%% Shared variables (explicit synchronization) and message passing (implicit synchronization) are identified as two basic approaches to communication~\cite{andrews1983concepts}.



%% Andrews and Schneider provide a dated but relevant overview of this work~.

%% We provide a brief review of influential A complete discussion of all of the models and techniques for reactive systems based on deterministic sequencing is beyond the scope of this proposal.
%% While dated,






%% An influential model based on shared variables is Dijkstra's Cooperating Sequential Processes which introduced the semaphore~\cite{dijkstra1965cooperating}.
%% An influential model based on message passing is Hoare's Communicating Sequential Processes which introduced the channel~\cite{hoare1978communicating}.



%% The two basic communication mechanisms are Communication The two basic techniques for structuring reactive p





%% A go




%% Solutions that separate synchronization and communication rely on synchronization primitives and shared variables for communication~\cite{andrews1983concepts}.
%% Solutions that combine synchronization and communication rely on message passing~\cite{andrews1983concepts}.
%% Dijkstra identifies the mutual exclusion problem of two processes and attributes an entirely software-based synchronization protocol to Dekker\cite{dijkstra1965cooperating}.
%% Dijkstra goes on to introduce the semaphore


%% The mutual exclusion problem was identified and software-based synchronization protocol is



%% Indeed, the preliminary research in reactive systems grew out of operating system research.
















%% Major contributions include basic mutual exclusion with busy waiting and spin locks (Dekker's algorithm~), semaphores

%% Important models in


%% Early work in reactive systems is concerned with
%% Early work in reactive systems grew out of operating systems research and was concerned

%% Modeling

%% Implementing


%% Perhaps the first reactive programs are the monitors (eventually operating systems) that grew out of the need to increase the utilization of early mainframes while providing for the interactive debugging of programs.
%% \emph{Multiprogrammed} systems such as the IBM STRETCH~\cite{codd1959multiprogramming} increased utilization by switching to another job when the current job was waiting on I/O.
%% \emph{Time sharing} or \emph{multitasking} systems such as the Compatible Time-Sharing System~\cite{corbato1962experimental} forces job switches at regular intervals prompting the development of interactive user programs.
%% The monitors for these systems are reactive programs as they were designed to run forever.
%% These developments led to the very influential MULTICS operating system~\cite{corbato1965introduction}.

%% The seminal paper on the theory of reactive systems is







%% The first major development was the introduction of \emph{multiprogramming} where

%% One such monitor,
%% patrick1987general


%% execute (transformational) programs

%% (batch processing) and debug transformational programs.
%% Brooks provides an overview of this process~\cite{brooks1995mythical}.
%% The two major developments were the idea of \emph{multiprogramming} and \emph{time sharing}.


%% The low speeds of I/O equipment in early mainframes prompted programmers to debug their programs at the machine console.
%% The introduction of high-speed printers allowed the entire memory of the machine to be dumped when a program encountered an error.
%% A programmer could then

%% ``on-machine debugging'' using a console in early mainframes.



%%  and increased leading to ``memory dumps'' where the entire memory of the machine would be dumped when an error was encounter and then analyzed by the programmer.
%% As memories grew larger it was not feasible to dump the entire memorybecame infeasible


%% Thus, perhaps the first ``reactive systems'' were the interactive debugging consoles on early mainframes.



%% the progression of these systems




%% \paragraph{History.}
%% The general


%% The early days of computing resembled the transformation

%% In the early days of computing, programmers would load a program, load its input

%% The earliest computers were operate

%% The earliest computers were designed to execute transformational programs.



%% Early computers were designed to run

%% An early but clearly identifiable reactive system was a wind tunnel analysis program at the National Advisory Committee for Aeronautics' Lewis Flight Propulsion Laboratory~\cite{Mersel:1956:PIU:1455410.1455428}.
%% Wind tunnel experiments would interrupt batch jobs on a UNIVAC 1103A to provide a qick

%% Baeten concludes that the first step towards developing models for reactive systems was ``abandoning the idea that a program is a transformation from input to output, replacing this by an approach where all intermediate states are important\cite{baeten2005brief}.''
%% The two dominant approaches to modeling reactive system are process algebras and state transition systems.
%% As implied by the name, the process algebra approach attempts to define laws of algebra or a calculus for specifying and reasoning about reactive systems~\cite{baeten2005brief}.
%% Influential process algebras include the Calculus of Communicating Systems~\cite{milner1982calculus} of Milner, Communicating Sequential Processes~\cite{hoare1978communicating} of Hoare, and the Algebra of Communicating Processes~\cite{bergstra1982fixed} of Berstra and Klop.
%% A typical formulation for a reactive system in a state transition systems such as the one presented by Manna and Pnueli in~\cite{manna1992temporal} characterizes a reactive system as a 4-tuple $(\Pi, \Sigma, T, \Theta)$ where $\Pi$ is ``a finite set of flexible \emph{state variables},'' $\Sigma$ is ``a set of states,'' $T$ is ``a finite set of transitions'', and $\Theta$ is ``an \emph{initial condition}.''
%% Equational reasoning, theorem proving, and model checking are three approaches used in the verification of reactive systems~\cite{baeten2005brief}.
%% We believe that state transition systems are a better foundation for a practical model for developing reactive systems since they seem to be grasped more readily when compared to typically more abstract process algebras.
%% The UNITY~\cite{chandy1989parallel} of Chandy and Misra and I/O Automata~\cite{nancy1996distributed} of Lynch are two popular models for reactive systems based on state transition systems.
%% The proposed work builds on the system structuring techniques, i.e., decomposition and composition, of UNITY and I/O Automata.

%% %% threads

%% %% actors

%% %% function call graphs
